# app/api/routes.py

import json
from datetime import UTC, datetime, timedelta

from flask import current_app, jsonify, request
from pydantic import ValidationError
from sqlalchemy import Text, and_, case, cast, distinct, func, or_
from sqlalchemy.dialects.postgresql import insert
from sqlalchemy.exc import DBAPIError, IntegrityError

from app.auth.decorators import admin_required, api_key_required
from app.extensions import cache, csrf, db, limiter, socketio
from app.metrics import (
    ANALYSIS_DURATION_SECONDS,
    DOCUMENTS_GENERATED_TOTAL,
    TESTS_COMPLETED_TOTAL,
)
from app.models import (
    Certificate,
    DocumentCounter,
    Fingerprint,
    ProctoringEvent,
    ResultMetadata,
    User,
)
from app.schemas.result_schema import SaveResultsRequest
from app.utils.analytics import (
    compare_mouse_trajectories,
    find_result_file_by_session_id,
)
from app.utils.document import generate_document_number
from app.utils.sanitizers import sanitize_filename
from app.utils.validators import (
    validate_event_type,
    validate_json_data,
    validate_session_id,
)

from . import api_bp

ALLOWED_PRESETS = {"all", "today", "week", "anomalies"}

# --- 1.4: –õ–∏–º–∏—Ç—ã —Ä–∞–∑–º–µ—Ä–∞ –∑–∞–ø—Ä–æ—Å–∞ ---
MAX_LOG_EVENT_SIZE = 1 * 1024 * 1024  # 1MB
MAX_SAVE_RESULTS_SIZE = 10 * 1024 * 1024  # 10MB (–¥–ª—è –¥–∞–Ω–Ω—ã—Ö —Å –¥–≤–∏–∂–µ–Ω–∏—è–º–∏ –º—ã—à–∏)
# 1.1: –ê–¢–û–ú–ê–†–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –°–û–ó–î–ê–ù–ò–Ø –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø (–¥–ª—è save_results)
# =============================================================================


def get_or_create_user(session, persistent_id, user_info_schema):
    """
    –ê—Ç–æ–º–∞—Ä–Ω–æ –ø–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∏—Å–ø–æ–ª—å–∑—É—è 'ON CONFLICT DO NOTHING'.
    –≠—Ç–æ —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É race condition.
    """
    if not user_info_schema:
        current_app.logger.warning(
            f"get_or_create_user: userInfo is missing for persistent_id {persistent_id}"
        )
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º None, —á—Ç–æ–±—ã save_results –º–æ–≥ –≤—ã–¥–∞—Ç—å –æ—à–∏–±–∫—É 400
        return None

    # –î–∞–Ω–Ω—ã–µ –∏–∑ Pydantic —Å—Ö–µ–º—ã
    user_data = {
        "lastname": user_info_schema.lastName,
        "firstname": user_info_schema.firstName,
        "middlename": user_info_schema.middleName,
        "position": user_info_schema.position,
        "persistent_id": persistent_id,
        "created_at": datetime.now(UTC),  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è
        "updated_at": datetime.now(UTC),  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Ä–µ–º—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
    }

    # 1. –ü—ã—Ç–∞–µ–º—Å—è –≤—Å—Ç–∞–≤–∏—Ç—å, –∏–≥–Ω–æ—Ä–∏—Ä—É—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç, –µ—Å–ª–∏ persistent_id —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    stmt = (
        insert(User)
        .values(**user_data)
        .on_conflict_do_nothing(
            index_elements=[
                "persistent_id"
            ]  # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É –≤–∞—Å –µ—Å—Ç—å unique constraint/index 'ix_users_persistent_id'
        )
    )
    session.execute(stmt)

    # 2. –¢–µ–ø–µ—Ä—å *–≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ* –ø–æ–ª—É—á–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    # (–õ–∏–±–æ –æ–Ω –±—ã–ª —Ç–æ–ª—å–∫–æ —á—Ç–æ —Å–æ–∑–¥–∞–Ω, –ª–∏–±–æ –æ–Ω —É–∂–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª)
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º .one(), —Ç.–∫. –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ç–µ–ø–µ—Ä—å –æ–±—è–∑–∞–Ω —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å
    try:
        user = session.query(User).filter_by(persistent_id=persistent_id).one()
        # (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ, –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–∂–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª, –∞ –¥–∞–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å
        if user.lastname != user_data["lastname"]:
            user.lastname = user_data["lastname"]
            user.firstname = user_data["firstname"]
            user.middlename = user_data["middlename"]
            user.position = user_data["position"]
            user.updated_at = datetime.now(UTC)

        return user
    except Exception as e:
        current_app.logger.error(
            f"Failed to get_or_create user {persistent_id} after UPSERT: {e}",
            exc_info=True,
        )
        return None


# =============================================================================
# API –≠–ù–î–ü–û–ò–ù–¢–´
# =============================================================================
@api_bp.route("/save_results", methods=["POST"])
@limiter.limit("30 per minute")  # 1.1: –£–≤–µ–ª–∏—á–µ–Ω –ª–∏–º–∏—Ç
@api_key_required
# @csrf.exempt # <-- 1.5: –£–î–ê–õ–ï–ù–û. CSRF-–∑–∞—â–∏—Ç–∞ –≤–∫–ª—é—á–µ–Ω–∞
def save_results():
    """
    –ê—Ç–æ–º–∞—Ä–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∑–∞–ø–∏—Å—å –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö —Ç–µ—Å—Ç–∞.
    """
    # --- 1.4: –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï DoS ---
    if request.content_length > MAX_SAVE_RESULTS_SIZE:
        return (
            jsonify({"status": "error", "message": "Result payload is too large"}),
            413,
        )
    try:
        # Pydantic-–≤–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥—è—â–µ–≥–æ JSON. –≠—Ç–æ—Ç –±–ª–æ–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.
        validated_data = SaveResultsRequest.model_validate(request.get_json())
    except ValidationError as e:
        current_app.logger.warning(
            f"Invalid data from {request.remote_addr}: {e.errors()}"
        )
        return (
            jsonify(
                {
                    "status": "error",
                    "message": "Invalid input data",
                    "details": e.errors(),
                }
            ),
            400,
        )

    # <--- –ò–ó–ú–ï–ù–ï–ù–ò–ï: –†–∞–±–æ—Ç–∞–µ–º –Ω–∞–ø—Ä—è–º—É—é —Å Pydantic-–æ–±—ä–µ–∫—Ç–æ–º, –∞ –Ω–µ —Å–æ —Å–ª–æ–≤–∞—Ä–µ–º ---
    session_id = validated_data.sessionId
    persistent_id = validated_data.persistentId.get("cookie")
    fp_hash = validated_data.fingerprint.get("privacySafeHash")

    if not persistent_id or not fp_hash:
        return (
            jsonify({"status": "error", "message": "Missing required identifiers"}),
            400,
        )

    try:
        # --- 1.1: –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï RACE CONDITION ---
        user = get_or_create_user(db.session, persistent_id, validated_data.userInfo)
        if not user:
            # –≠—Ç–æ –º–æ–∂–µ—Ç —Å–ª—É—á–∏—Ç—å—Å—è, –µ—Å–ª–∏ userInfo –±—ã–ª None –∏–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤ get_or_create
            return (
                jsonify(
                    {
                        "status": "error",
                        "message": "Failed to get or create user profile",
                    }
                ),
                400,
            )

            # –ù–ï –î–ï–õ–ê–ï–ú FLUSH –ó–î–ï–°–¨

        # --- "–¶–∏—Ñ—Ä–æ–≤–æ–π –æ—Ç–ø–µ—á–∞—Ç–æ–∫" (Fingerprint) ---
        fingerprint = Fingerprint.query.filter_by(fingerprint_hash=fp_hash).first()
        if not fingerprint:
            fp_data = validated_data.fingerprint.get("privacySafe", {})
            fingerprint = Fingerprint(
                fingerprint_hash=fp_hash,
                user_agent=fp_data.get("userAgent"),
                platform=fp_data.get("platform"),
                webgl_renderer=fp_data.get("webGLRenderer"),
            )
            db.session.add(fingerprint)
        else:
            fingerprint.last_seen = datetime.now(UTC)

        # --- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (ResultMetadata) - –û–ë–ù–û–í–õ–ï–ù–ò–ï ---
        result = db.session.get(ResultMetadata, session_id)
        if not result:
            current_app.logger.error(
                f"Attempted to save results for non-existent session: {session_id}"
            )
            return (
                jsonify(
                    {"status": "error", "message": f"Session {session_id} not found"}
                ),
                404,
            )

            # –†–∞–∑–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ Pydantic-–æ–±—ä–µ–∫—Ç–∞
            start_time_dt = validated_data.sessionMetrics.startTime
            end_time_dt = validated_data.sessionMetrics.endTime
            score = validated_data.testResults.percentage  # –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–∏–∂–µ
            start_time_from_dict = (
                validated_data.dict().get("sessionMetrics", {}).get("startTime")
            )
            end_time_from_dict = (
                validated_data.dict().get("sessionMetrics", {}).get("endTime")
            )

            # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç
            if not isinstance(start_time_dt, datetime) and start_time_from_dict:
                current_app.logger.warning(
                    f"Pydantic might have failed to parse startTime: '{start_time_from_dict}' for session {session_id}. Using raw value if available."
                )
                # –ï—Å–ª–∏ start_time_dt –Ω–µ datetime, –º–æ–∂–Ω–æ –ø–æ–ø—ã—Ç–∞—Ç—å—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å start_time_from_dict –∑–¥–µ—Å—å,
                # –Ω–æ Pydantic –¥–æ–ª–∂–µ–Ω –±—ã–ª –≤—ã–¥–∞—Ç—å –æ—à–∏–±–∫—É –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ä–∞–Ω—å—à–µ, –µ—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –Ω–µ–≤–µ—Ä–Ω—ã–π.
            if not isinstance(end_time_dt, datetime) and end_time_from_dict:
                current_app.logger.warning(
                    f"Pydantic might have failed to parse endTime: '{end_time_from_dict}' for session {session_id}. Using raw value if available."
                )

        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∑–∞–ø–∏—Å–∏
        result.user_id = user.id
        result.fingerprint_hash = fp_hash
        result.test_type = validated_data.test_type
        result.score = validated_data.testResults.percentage
        result.start_time = validated_data.sessionMetrics.startTime
        result.end_time = validated_data.sessionMetrics.endTime
        result.raw_data = validated_data.model_dump(mode="json", by_alias=True)
        result.client_ip = request.remote_addr

        # --- –ù–æ–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –°–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç ---
        document_number = None
        passed = result.score >= current_app.config.get("PASSING_SCORE_THRESHOLD", 80)
        if passed:
            document_number = generate_document_number(db.session)
            result.document_number = document_number

            certificate = Certificate(
                document_number=document_number,
                user_fullname=user.full_name,
                user_position=user.position,
                test_type=validated_data.test_type,
                score_percentage=result.score,
                session_id=session_id,
            )
            db.session.add(certificate)

        # --- –§–∏–∫—Å–∞—Ü–∏—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ ---
        db.session.commit()

        # --- –î–µ–π—Å—Ç–≤–∏—è –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è ---
        cache.delete_memoized(get_results_api)
        cache.delete_memoized(get_certificates)
        socketio.emit("update_needed", {"type": "new_result", "session_id": session_id})

        result_status = "passed" if passed else "failed"
        TESTS_COMPLETED_TOTAL.labels(
            test_type=validated_data.test_type, result=result_status
        ).inc()
        if document_number:
            DOCUMENTS_GENERATED_TOTAL.labels(test_type=validated_data.test_type).inc()

        current_app.logger.info(
            f"Results saved: session={session_id}, score={result.score}%, doc={document_number}"
        )

        response = {
            "status": "success",
            "message": "Results saved successfully",
            "session_id": session_id,
        }
        if document_number:
            response["officialDocumentNumber"] = document_number

        return jsonify(response), 201

    except IntegrityError as e:
        db.session.rollback()
        current_app.logger.error(
            f"DB integrity error in save_results: {e}", exc_info=True
        )
        return jsonify({"status": "error", "message": "Data conflict"}), 409
    except Exception as e:
        db.session.rollback()
        current_app.logger.error(
            f"Unexpected error in save_results: {e}", exc_info=True
        )
        return jsonify({"status": "error", "message": "Internal server error"}), 500


@api_bp.route("/log_event", methods=["POST"])
@limiter.limit("60 per minute")
# @csrf.exempt # <-- 1.5: –£–î–ê–õ–ï–ù–û. CSRF-–∑–∞—â–∏—Ç–∞ –≤–∫–ª—é—á–µ–Ω–∞
@api_key_required
def log_event():

    # --- 1.4: –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï DoS ---
    if request.content_length > MAX_LOG_EVENT_SIZE:
        return jsonify({"status": "error", "message": "Request is too large"}), 413

    # –í—ã–∑—ã–≤–∞–µ–º get_json() –ë–ï–ó –∞—Ä–≥—É–º–µ–Ω—Ç–∞ max_content_length
    data = request.get_json()
    if not data:
        return jsonify({"status": "error", "message": "No data"}), 400

    is_valid, error_msg = validate_json_data(data, ["sessionId", "eventType"])
    if not is_valid:
        return jsonify({"status": "error", "message": error_msg}), 400

    session_id = data["sessionId"]
    event_type = data["eventType"]
    if not validate_session_id(session_id):
        return jsonify({"status": "error", "message": "Invalid session ID"}), 400
    if not validate_event_type(event_type):
        return jsonify({"status": "error", "message": "Invalid event type"}), 400

    try:
        # --- –õ–û–ì–ò–ö–ê –ü–†–û–í–ï–†–ö–ò –ò –°–û–ó–î–ê–ù–ò–Ø –†–û–î–ò–¢–ï–õ–¨–°–ö–û–ô –ó–ê–ü–ò–°–ò ---
        result_metadata = db.session.get(ResultMetadata, session_id)
        if not result_metadata:
            # –ï—Å–ª–∏ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∞—è –∑–∞–ø–∏—Å—å –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Å–æ–∑–¥–∞–µ–º "—á–µ—Ä–Ω–æ–≤–∏–∫"
            result_metadata = ResultMetadata(session_id=session_id, test_type="pending")
            db.session.add(result_metadata)
        # --- –ö–û–ù–ï–¶ –ù–û–í–û–ô –õ–û–ì–ò–ö–ò ---

        # –õ–æ–≥–∏–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å–∞–º–æ–≥–æ —Å–æ–±—ã—Ç–∏—è (proctoring_event)
        details = data.get("details", {})
        details["ip"] = request.remote_addr

        event = ProctoringEvent(
            session_id=session_id,
            event_type=event_type,
            event_timestamp=datetime.fromisoformat(
                data.get("eventTimestamp", datetime.now(UTC).isoformat()).replace(
                    "Z", ""
                )
            ),
            details=details,
            persistent_id=details.get("persistentId"),
            client_ip=request.remote_addr,
            page=details.get("page"),
        )
        db.session.add(event)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏ —Å–æ–±—ã—Ç–∏–µ, –∏, –≤–æ–∑–º–æ–∂–Ω–æ, –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å –æ —Å–µ—Å—Å–∏–∏ –≤ –æ–¥–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
        db.session.commit()

        return jsonify({"status": "success"}), 200

    except Exception as e:
        db.session.rollback()
        current_app.logger.error(f"Error in log_event: {e}", exc_info=True)
        return jsonify({"status": "error", "message": "Internal error"}), 500


@api_bp.route("/get_behavior_analysis", methods=["GET"])
@admin_required
@cache.memoize(timeout=120)
def get_behavior_analysis():
    # ... (–í–µ—Å—å –∫–æ–¥ —ç—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –æ—Å—Ç–∞–µ—Ç—Å—è –∫–∞–∫ –≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–º –æ—Ç–≤–µ—Ç–µ)
    try:
        # Configuration
        config = current_app.config
        thresholds = config.get(
            "BEHAVIOR_THRESHOLDS",
            {"min_score": 90, "max_test_duration_sec": 180, "min_engagement_score": 15},
        )

        # --- üëá –ò–ó–ú–ï–ù–ï–ù–ò–ï: –õ–û–ì–ò–ö–ê SUBQUERY üëá ---

        # –®–∞–≥ 1: CTE –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è '—á–∏—Å—Ç—ã—Ö' –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON
        # –≠—Ç–æ –¥–µ–ª–∞–µ—Ç –ø–æ—Å–ª–µ–¥—É—é—â—É—é –∞–≥—Ä–µ–≥–∞—Ü–∏—é —á–∏—â–µ –∏ –±—ã—Å—Ç—Ä–µ–µ
        engagement_events = (
            db.session.query(
                ProctoringEvent.persistent_id,
                ProctoringEvent.client_ip,
                ProctoringEvent.event_timestamp,
                # –ò–∑–≤–ª–µ–∫–∞–µ–º 'duration'
                case(
                    (
                        ProctoringEvent.event_type == "module_view_time",
                        func.cast(
                            ProctoringEvent.details["duration"].as_string(),
                            db.Integer,
                        ),
                    ),
                    else_=0,
                ).label("view_time"),
                # –ò–∑–≤–ª–µ–∫–∞–µ–º 'scroll_depth'
                case(
                    (
                        ProctoringEvent.event_type == "scroll_depth_milestone",
                        func.cast(
                            func.replace(
                                ProctoringEvent.details["depth"].as_string(),
                                "%",
                                "",
                            ),
                            db.Integer,
                        ),
                    ),
                    else_=0,
                ).label("scroll_depth"),
                # –ò–∑–≤–ª–µ–∫–∞–µ–º 'self_check'
                case(
                    (ProctoringEvent.event_type == "self_check_answered", 1),
                    else_=0,
                ).label("self_check"),
            )
            .filter(
                ProctoringEvent.event_type.in_(
                    [
                        "study_started",  # study_started –Ω—É–∂–µ–Ω –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏
                        "module_view_time",
                        "scroll_depth_milestone",
                        "self_check_answered",
                    ]
                )
            )
            .cte("engagement_events")
        )

        # –®–∞–≥ 2: –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –í–°–ï —Å–µ—Å—Å–∏–∏ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        # (–≤–º–µ—Å—Ç–æ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –ø–æ session_id)
        study_subquery = (
            db.session.query(
                engagement_events.c.persistent_id,
                engagement_events.c.client_ip,
                # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –≤—Å–µ —Å–µ—Å—Å–∏–∏ –æ–±—É—á–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                func.sum(engagement_events.c.view_time).label("total_view_time"),
                func.max(engagement_events.c.scroll_depth).label("max_scroll_depth"),
                func.sum(engagement_events.c.self_check).label("self_check_count"),
                # –ù–∞–º —Ç–∞–∫–∂–µ –Ω—É–∂–Ω–æ —Å–∞–º–æ–µ —Ä–∞–Ω–Ω–µ–µ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –¥–ª—è join
                func.min(engagement_events.c.event_timestamp).label("first_study_time"),
            )
            .group_by(
                engagement_events.c.persistent_id,
                engagement_events.c.client_ip,
            )
            .subquery()
        )
        # --- üëÜ –ö–û–ù–ï–¶ –ò–ó–ú–ï–ù–ï–ù–ò–Ø SUBQUERY üëÜ ---

        # –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—Ä–æ—Å (—Ç–µ–ø–µ—Ä—å —Å–æ–µ–¥–∏–Ω—è–µ—Ç 1 —Ç–µ—Å—Ç —Å 1 –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π –æ–±—É—á–µ–Ω–∏—è)
        suspicious_query = (
            db.session.query(
                ResultMetadata.session_id,
                ResultMetadata.score,
                ResultMetadata.test_type,
                ResultMetadata.client_ip,
                User.lastname,
                User.firstname,
                User.middlename,
                User.position,
                func.extract(
                    "epoch", ResultMetadata.end_time - ResultMetadata.start_time
                ).label("test_duration"),
                # –≠—Ç–∏ –ø–æ–ª—è —Ç–µ–ø–µ—Ä—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç –°–£–ú–ú–£ –≤—Å–µ—Ö —Å–µ—Å—Å–∏–π –æ–±—É—á–µ–Ω–∏—è
                study_subquery.c.total_view_time,
                study_subquery.c.max_scroll_depth,
                study_subquery.c.self_check_count,
            )
            .join(User, ResultMetadata.user_id == User.id)
            .outerjoin(  # –ò—Å–ø–æ–ª—å–∑—É–µ–º outerjoin, –Ω–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ –æ–±—É—á–µ–Ω–∏—è –Ω–µ –±—ã–ª–æ
                study_subquery,
                and_(
                    or_(
                        and_(  # –Ø–≤–Ω–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ ID, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ NULL
                            User.persistent_id.isnot(None),
                            study_subquery.c.persistent_id.isnot(None),
                            User.persistent_id == study_subquery.c.persistent_id,
                        ),
                        and_(  # –Ø–≤–Ω–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ IP, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ NULL
                            ResultMetadata.client_ip.isnot(None),
                            study_subquery.c.client_ip.isnot(None),
                            ResultMetadata.client_ip == study_subquery.c.client_ip,
                        ),
                    ),
                    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –æ–±—É—á–µ–Ω–∏–µ –±—ã–ª–æ –¥–æ —Ç–µ—Å—Ç–∞
                    study_subquery.c.first_study_time < ResultMetadata.start_time,
                    # (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø–æ–∏—Å–∫ –æ–±—É—á–µ–Ω–∏—è (–Ω–∞–ø—Ä. –∑–∞ 24 —á–∞—Å–∞ –¥–æ —Ç–µ—Å—Ç–∞)
                    study_subquery.c.first_study_time
                    > ResultMetadata.start_time - timedelta(hours=24),
                ),
            )
            .filter(
                # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–µ—Å—Ç—ã —Å –≤—ã—Å–æ–∫–∏–º –±–∞–ª–ª–æ–º –∏ –±—ã—Å—Ç—Ä—ã–º –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ–º
                ResultMetadata.score >= thresholds["min_score"],
                func.extract(
                    "epoch", ResultMetadata.end_time - ResultMetadata.start_time
                )
                < thresholds["max_test_duration_sec"],
            )
            # --- üëá –ù–û–í–û–ï: –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç, —á—Ç–æ–±—ã —É–±—Ä–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –æ—Ç JOIN üëá ---
            .group_by(
                ResultMetadata.session_id,
                User.id,  # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ —Å–µ—Å—Å–∏–∏
                study_subquery.c.total_view_time,
                study_subquery.c.max_scroll_depth,
                study_subquery.c.self_check_count,
            )
            # --- üëÜ ---
        )

        # Execute query and process results
        suspicious_sessions = []
        for row in suspicious_query.all():
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º engagement_score (—Ç–µ–ø–µ—Ä—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –û–ë–©–ï–ô —Å—É–º–º—ã –æ–±—É—á–µ–Ω–∏—è)
            engagement_score = 0
            if row.total_view_time:
                engagement_score += int(
                    row.total_view_time / 60
                )  # 1 –æ—á–∫–æ –∑–∞ –º–∏–Ω—É—Ç—É –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
            if row.max_scroll_depth:
                if row.max_scroll_depth >= 95:
                    engagement_score += 10
                elif row.max_scroll_depth >= 50:
                    engagement_score += 5
            if row.self_check_count:
                engagement_score += row.self_check_count * 2  # 2 –æ—á–∫–∞ –∑–∞ —Å–∞–º–æ–ø—Ä–æ–≤–µ—Ä–∫—É

            # Check if suspicious (–æ–±—â–∏–π engagement_score < –ø–æ—Ä–æ–≥–∞)
            if engagement_score < thresholds["min_engagement_score"]:
                suspicious_sessions.append(
                    {
                        "sessionId": row.session_id,
                        "userInfo": {
                            "lastName": row.lastname,
                            "firstName": row.firstname,
                            "middleName": row.middlename,
                            "position": row.position,
                        },
                        "testResult": {
                            "score": row.score,
                            "duration": (
                                int(row.test_duration) if row.test_duration else 0
                            ),
                        },
                        "studyInfo": {
                            "totalStudyTimeSec": (
                                int(row.total_view_time) if row.total_view_time else 0
                            ),
                            "engagementScore": engagement_score,
                        },
                        "reason": f"High score ({row.score}%) with fast completion ({int(row.test_duration)}s) and low TOTAL study engagement (Score: {engagement_score})",
                    }
                )

        current_app.logger.info(
            f"Behavior analysis found {len(suspicious_sessions)} suspicious sessions"
        )
        return jsonify(suspicious_sessions), 200

    except Exception as e:
        current_app.logger.error(f"Error in behavior analysis: {e}", exc_info=True)
        return jsonify({"status": "error", "message": "Analysis failed"}), 500


from app.utils.analytics import find_result_file_by_session_id


@api_bp.route("/get_full_result/<session_id>", methods=["GET"])
@admin_required
def get_full_result_data(session_id: str):
    """
    –ù–∞—Ö–æ–¥–∏—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω—ã–µ JSON-–¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.
    """
    # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ–ø–µ—Ä—å —Å–∞–º–∞ –¥–µ–ª–∞–µ—Ç –≤–∞–ª–∏–¥–∞—Ü–∏—é –∏ –∏—â–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –ë–î
    result_data = find_result_file_by_session_id(session_id)

    if result_data:
        # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–∞–π–¥–µ–Ω—ã, –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Ö
        return jsonify(result_data), 200
    else:
        # –ï—Å–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è –≤–µ—Ä–Ω—É–ª–∞ None (ID –Ω–µ–≤–∞–ª–∏–¥–µ–Ω –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω), –æ—Ç–¥–∞–µ–º 404
        return jsonify({"status": "error", "message": "Result not found"}), 404


from app.utils.analytics import (
    compare_mouse_trajectories,
    find_result_file_by_session_id,
)


@api_bp.route("/analyze_mouse", methods=["POST"])
@admin_required  # <--- –î–û–ë–ê–í–¨–¢–ï –≠–¢–û–¢ –î–ï–ö–û–†–ê–¢–û–†
@limiter.limit("5 per minute")
def analyze_mouse():
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç—å —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π –º—ã—à–∏, –ø–æ–ª—É—á–∞—è –¥–∞–Ω–Ω—ã–µ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –ë–î,
    –∏ –∏–∑–º–µ—Ä—è–µ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–π –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.
    """
    try:
        data = request.get_json()
        session_ids = data.get("session_ids")

        if not session_ids or len(session_ids) < 2:
            return jsonify({"error": "–ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2 —Å–µ—Å—Å–∏–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"}), 400

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –¥–∞–Ω–Ω—ã—Ö, –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –∏–∑ –ë–î
        trajectories = {}
        for sid in session_ids:
            result_data = find_result_file_by_session_id(sid)
            if not result_data:
                current_app.logger.warning(f"–î–∞–Ω–Ω—ã–µ –¥–ª—è —Å–µ—Å—Å–∏–∏ {sid} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –ë–î")
                continue

            per_question = result_data.get("behavioralMetrics", {}).get(
                "perQuestion", []
            )
            trajectories[sid] = {}
            for i, q_data in enumerate(per_question):
                movements = q_data.get("mouseMovements")
                if movements:
                    trajectories[sid][i] = movements

        # –õ–æ–≥–∏–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π
        results = {}
        sid_list = list(session_ids)

        for i in range(len(sid_list)):
            for j in range(i + 1, len(sid_list)):
                s1, s2 = sid_list[i], sid_list[j]
                pair_key = f"{s1}_vs_{s2}"
                results[pair_key] = {}

                common_qs = set(trajectories.get(s1, {}).keys()) & set(
                    trajectories.get(s2, {}).keys()
                )

                for q_idx in common_qs:
                    t1 = trajectories[s1][q_idx]
                    t2 = trajectories[s2][q_idx]

                    # <--- –ù–ê–ß–ê–õ–û –ò–ó–ú–ï–ù–ï–ù–ò–Ø: –ò–ó–ú–ï–†–ï–ù–ò–ï –î–õ–ò–¢–ï–õ–¨–ù–û–°–¢–ò --->
                    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–∞–π–º–µ—Ä –ø–µ—Ä–µ–¥ –≤—ã–∑–æ–≤–æ–º —Ä–µ—Å—É—Ä—Å–æ–µ–º–∫–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
                    with ANALYSIS_DURATION_SECONDS.time():
                        similarity = compare_mouse_trajectories(t1, t2)
                    # –ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –±–ª–æ–∫–∞ `with` –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –±—É–¥–µ—Ç
                    # –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø–∏—Å–∞–Ω–∞ –≤ –º–µ—Ç—Ä–∏–∫—É Prometheus.
                    # <--- –ö–û–ù–ï–¶ –ò–ó–ú–ï–ù–ï–ù–ò–Ø --->

                    results[pair_key][q_idx] = round(similarity, 1)

        return jsonify(results), 200

    except Exception as e:
        current_app.logger.error(f"–û—à–∏–±–∫–∞ –≤ –∞–Ω–∞–ª–∏–∑–µ –¥–≤–∏–∂–µ–Ω–∏–π –º—ã—à–∏: {e}", exc_info=True)
        return jsonify({"status": "error", "message": "Internal server error"}), 500


@api_bp.route("/get_results", methods=["GET"])
@admin_required
@cache.cached(timeout=60, query_string=True)
def get_results_api():
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π –∏–∑ –ë–î.
    –§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ —Å—Ç–∞—Ç—É—Å—É –ò –ø–æ –ø—Ä–µ—Å–µ—Ç–∞–º (—Å–µ–≥–æ–¥–Ω—è, –Ω–µ–¥–µ–ª—è, –∞–Ω–æ–º–∞–ª–∏–∏).
    """
    try:
        page = request.args.get("page", 1, type=int)
        per_page = request.args.get("per_page", 20, type=int)

        # --- üëá –ù–û–í–´–ô –ö–û–î: –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç—É—Å –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ üëá ---
        status = request.args.get(
            "status", "", type=str
        )  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é "" (–í—Å–µ —Å—Ç–∞—Ç—É—Å—ã)
        # --- üëÜ –ö–û–ù–ï–¶ –ù–û–í–û–ì–û –ö–û–î–ê üëÜ ---
        preset = request.args.get("preset", "all", type=str)

        if preset not in ALLOWED_PRESETS:
            return jsonify({"status": "error", "message": "Invalid preset value"}), 400
        max_per_page = current_app.config.get("MAX_RESULTS_PER_PAGE", 1000)

        if not (1 <= page <= 1000 and 1 <= per_page <= max_per_page):
            return (
                jsonify(
                    {"status": "error", "message": "Invalid pagination parameters"}
                ),
                400,
            )

        # –û—Å–Ω–æ–≤–∞ –∑–∞–ø—Ä–æ—Å–∞: –ø–æ–ª—É—á–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏ —Å—Ä–∞–∑—É –ø–æ–¥–≥—Ä—É–∂–∞–µ–º —Å–≤—è–∑–∞–Ω–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è,
        base_query = ResultMetadata.query.options(db.joinedload(ResultMetadata.user))
        # --- üëá –î–û–ë–ê–í–õ–ï–ù–´ –§–ò–õ–¨–¢–†–´ –î–õ–Ø –ó–ê–í–ï–†–®–ï–ù–ù–´–• –¢–ï–°–¢–û–í üëá ---
        # --- üëá –ò–ó–ú–ï–ù–ï–ù–ò–ï: –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ —Ñ–∏–ª—å—Ç—Ä—ã –≤–º–µ—Å—Ç–æ "–∂–µ—Å—Ç–∫–∏—Ö" üëá ---
        if status == "completed":
            # "–ó–∞–≤–µ—Ä—à–µ–Ω" - –µ—Å—Ç—å –æ—Ü–µ–Ω–∫–∞, –≤—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
            base_query = base_query.filter(
                ResultMetadata.score.isnot(None),
                ResultMetadata.end_time.isnot(None),
                ResultMetadata.user_id.isnot(None),
            )
        elif status == "in_progress" or status == "abandoned":
            # "–í –ø—Ä–æ—Ü–µ—Å—Å–µ" –∏–ª–∏ "–ü—Ä–µ—Ä–≤–∞–Ω" - —ç—Ç–æ –∑–∞–ø–∏—Å–∏, —Å–æ–∑–¥–∞–Ω–Ω—ã–µ log_event,
            # –Ω–æ –µ—â–µ –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ save_results.
            # –£ –Ω–∏—Ö –Ω–µ—Ç user_id –∏–ª–∏ end_time.
            base_query = base_query.filter(
                ResultMetadata.user_id.is_(None),
                ResultMetadata.end_time.is_(None),
                # 'pending' —Ç–∞–∫–∂–µ –ø–æ–ø–∞–¥–µ—Ç —Å—é–¥–∞, —Ç.–∫. —É –Ω–µ–≥–æ user_id is None
            )

        # --- üëá –ù–û–í–´–ô –ö–û–î: –§–∏–ª—å—Ç—Ä—ã –ø–æ –ü–†–ï–°–ï–¢–ê–ú (–¥–∞—Ç—ã –∏ –∞–Ω–æ–º–∞–ª–∏–∏) üëá ---
        now = datetime.now(UTC)

        if preset == "today":
            today_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
            base_query = base_query.filter(ResultMetadata.start_time >= today_start)

        elif preset == "week":
            week_start = (now - timedelta(days=now.weekday())).replace(
                hour=0, minute=0, second=0, microsecond=0
            )
            base_query = base_query.filter(ResultMetadata.start_time >= week_start)

        elif preset == "anomalies":
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ—Ä–æ–≥–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
            focus_thresh = current_app.config.get("FOCUS_THRESHOLD", 5)
            blur_thresh = current_app.config.get("BLUR_THRESHOLD", 60)
            print_thresh = current_app.config.get("PRINT_THRESHOLD", 0)

            # –§–∏–ª—å—Ç—Ä –ø–æ JSON-–ø–æ–ª—é raw_data. –≠—Ç–æ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ –¥–ª—è PostgreSQL (JSONB)
            # –ú—ã –∏—â–µ–º, –≥–¥–µ ('sessionMetrics' -> 'totalFocusLoss')::int > focus_thresh
            base_query = base_query.filter(
                ResultMetadata.raw_data.isnot(None),
                or_(
                    ResultMetadata.raw_data.op("->")("sessionMetrics")
                    .op("->>")("totalFocusLoss")
                    .cast(db.Integer)
                    > focus_thresh,
                    ResultMetadata.raw_data.op("->")("sessionMetrics")
                    .op("->>")("totalBlurTime")
                    .cast(db.Float)
                    > blur_thresh,
                    ResultMetadata.raw_data.op("->")("sessionMetrics")
                    .op("->>")("printAttempts")
                    .cast(db.Integer)
                    > print_thresh,
                ),
            )
        # --- üëÜ –ö–û–ù–ï–¶ –ù–û–í–û–ì–û –ö–û–î–ê üëÜ ---

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –≤—Å–µ–≥–¥–∞
        base_query = base_query.order_by(ResultMetadata.start_time.desc())

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—É—é –ø–∞–≥–∏–Ω–∞—Ü–∏—é SQLAlchemy - —ç—Ç–æ –ø—Ä–æ—â–µ –∏ –Ω–∞–¥–µ–∂–Ω–µ–µ
        pagination = base_query.paginate(page=page, per_page=per_page, error_out=False)
        results_from_db = pagination.items
        total = pagination.total

        results = []
        for row in results_from_db:
            # score —Ç–µ–ø–µ—Ä—å —Ç–æ—á–Ω–æ –Ω–µ None –∏–∑-–∑–∞ —Ñ–∏–ª—å—Ç—Ä–∞ .isnot(None)
            score = row.score if row.score is not None else 0

            # ... (–ª–æ–≥–∏–∫–∞ grade_class, grade_text) ...
            if score >= 90:
                grade_class, grade_text = "excellent", "–û—Ç–ª–∏—á–Ω–æ"
            elif score >= 80:
                grade_class, grade_text = "good", "–•–æ—Ä–æ—à–æ"
            elif score >= 70:
                grade_class, grade_text = "satisfactory", "–£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ"
            elif score >= 60:
                grade_class, grade_text = "unsatisfactory", "–ù–µ—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ"
            else:
                grade_class, grade_text = "poor", "–ü–ª–æ—Ö–æ"

            # --- üëá –ò–ó–ú–ï–ù–ï–ù–ò–ï: –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ–± –∞–Ω–æ–º–∞–ª–∏—è—Ö –∏–∑ raw_data üëá ---
            sm_raw = (row.raw_data or {}).get("sessionMetrics", {})
            session_metrics = {
                "startTime": row.start_time.isoformat() if row.start_time else None,
                "endTime": row.end_time.isoformat() if row.end_time else None,
                # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞ –∞–Ω–æ–º–∞–ª–∏–π
                "totalFocusLoss": sm_raw.get("totalFocusLoss", 0),
                "totalBlurTime": sm_raw.get("totalBlurTime", 0),
                "printAttempts": sm_raw.get("printAttempts", 0),
            }
            # --- üëÜ –ö–û–ù–ï–¶ –ò–ó–ú–ï–ù–ï–ù–ò–Ø üëÜ ---

            results.append(
                {
                    "sessionId": row.session_id,
                    "testType": row.test_type,
                    "clientIp": row.client_ip,
                    "userInfo": {
                        # –≠—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–Ω–æ–≤–∞ –∫—Ä–∏—Ç–∏—á–Ω–∞
                        "lastName": row.user.lastname if row.user else None,
                        "firstName": row.user.firstname if row.user else None,
                    },
                    "testResults": {
                        "percentage": score,
                        "grade": {"class": grade_class, "text": grade_text},
                    },
                    "sessionMetrics": session_metrics,
                }
            )

        return jsonify(
            {"results": results, "page": page, "per_page": per_page, "total": total}
        )

    except Exception as e:
        current_app.logger.error(f"Error in get_results_api: {e}", exc_info=True)
        return jsonify({"status": "error", "message": "Error retrieving results"}), 500


@api_bp.route("/get_certificates", methods=["GET"])
@admin_required
@cache.memoize(timeout=360)
def get_certificates():
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–µ—Å—Ç—Ä –≤—Å–µ—Ö –≤—ã–¥–∞–Ω–Ω—ã—Ö —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤ –∏–∑ –ë–î.
    4.4: –ò–°–ü–†–ê–í–õ–ï–ù–û: –î–æ–±–∞–≤–ª–µ–Ω–∞ –ø–∞–≥–∏–Ω–∞—Ü–∏—è.
    """
    try:
        page = request.args.get("page", 1, type=int)
        per_page = request.args.get("per_page", 50, type=int)

        pagination = Certificate.query.order_by(Certificate.issue_date.desc()).paginate(
            page=page, per_page=per_page, error_out=False
        )

        certificates = [cert.to_dict() for cert in pagination.items]

        return (
            jsonify(
                {
                    "certificates": certificates,
                    "total": pagination.total,
                    "page": page,
                    "per_page": per_page,
                    "has_next": pagination.has_next,
                    "has_prev": pagination.has_prev,
                }
            ),
            200,
        )

    except Exception as e:
        current_app.logger.error(f"Error in get_certificates: {e}", exc_info=True)
        return jsonify({"status": "error", "message": "Internal server error"}), 500


@api_bp.route("/get_events/<session_id>", methods=["GET"])
@admin_required
def get_events(session_id: str):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ —Å–æ–±—ã—Ç–∏—è –ø—Ä–æ–∫—Ç–æ—Ä–∏–Ω–≥–∞ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π —Å–µ—Å—Å–∏–∏."""
    try:
        if not validate_session_id(session_id):
            return jsonify({"status": "error", "message": "Invalid session ID"}), 400

        events_from_db = (
            ProctoringEvent.query.filter_by(session_id=session_id)
            .order_by(ProctoringEvent.event_timestamp.asc())
            .all()
        )
        events = [event.to_dict() for event in events_from_db]

        return jsonify(events), 200
    except Exception as e:
        current_app.logger.error(
            f"Error in get_events for session {session_id}: {e}", exc_info=True
        )
        return jsonify({"status": "error", "message": "Internal server error"}), 500


@api_bp.route("/get_abandoned_sessions", methods=["GET"])
@admin_required
@cache.memoize(timeout=60)
def get_abandoned_sessions():
    """
    –ù–∞—Ö–æ–¥–∏—Ç –ø—Ä–µ—Ä–≤–∞–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç fallback –Ω–∞ userInfo –∏–∑ JSON-–¥–µ—Ç–∞–ª–µ–π.
    """
    try:
        passing_score = current_app.config.get("PASSING_SCORE_THRESHOLD", 80)
        # CTE –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤—Å–µ—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–π
        successful_sessions = (
            db.session.query(ResultMetadata.session_id)
            .filter(
                ResultMetadata.session_id.isnot(None),
                ResultMetadata.score
                >= passing_score,  # <-- –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é passing_score
            )
            .cte("successful_sessions")
        )

        first_event = (
            db.session.query(
                ProctoringEvent.session_id,
                ProctoringEvent.event_type,
                ProctoringEvent.event_timestamp,
                ProctoringEvent.details,
                ProctoringEvent.persistent_id,
                func.row_number()
                .over(
                    partition_by=ProctoringEvent.session_id,
                    order_by=ProctoringEvent.event_timestamp.asc(),
                )
                .label("rn"),
            )
            .filter(
                ProctoringEvent.event_type.in_(
                    ["test_started", "study_started"]
                ),  # –î–æ–±–∞–≤–ª–µ–Ω–∞ –∑–∞–ø—è—Ç–∞—è
                ProctoringEvent.details.isnot(None),
            )
            .cte("first_event")
        )

        # –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –±—Ä–æ—à–µ–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–π
        abandoned_query = (
            db.session.query(
                ProctoringEvent.session_id,
                func.max(first_event.c.event_type).label("session_type"),
                func.min(ProctoringEvent.event_timestamp).label("start_time"),
                func.max(cast(first_event.c.details, Text)).label(
                    "first_event_details_text"
                ),
                func.max(first_event.c.persistent_id).label("persistent_id"),
                # ... (–æ—Å—Ç–∞–ª—å–Ω—ã–µ –∞–≥—Ä–µ–≥–∞—Ç–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏) ...
                func.count(case((ProctoringEvent.event_type == "focus_loss", 1))).label(
                    "focus_loss_count"
                ),
                func.count(
                    case((ProctoringEvent.event_type == "screenshot_attempt", 1))
                ).label("screenshot_count"),
                func.count(
                    case((ProctoringEvent.event_type == "print_attempt", 1))
                ).label("print_count"),
            )
            .select_from(ProctoringEvent)
            .outerjoin(
                first_event,
                and_(
                    ProctoringEvent.session_id == first_event.c.session_id,
                    first_event.c.rn == 1,
                ),
            )
            .filter(
                ~ProctoringEvent.session_id.in_(
                    db.session.query(successful_sessions.c.session_id)
                )
            )
            .group_by(ProctoringEvent.session_id)
            .order_by(func.min(ProctoringEvent.event_timestamp).desc())
        )

        # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
        abandoned_sessions = abandoned_query.all()

        if not abandoned_sessions:
            current_app.logger.info("No abandoned/unsuccessful sessions found.")
            return jsonify([]), 200

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ persistent_id –¥–ª—è batch-–∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        persistent_ids = {
            s.persistent_id for s in abandoned_sessions if s.persistent_id
        }

        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è—Ö –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º
        users_map = {}
        if persistent_ids:
            users = User.query.filter(User.persistent_id.in_(persistent_ids)).all()
            users_map = {user.persistent_id: user for user in users}

        # –ú–∞–ø–ø–∏–Ω–≥ —Ç–∏–ø–æ–≤ —Å–µ—Å—Å–∏–π
        session_type_map = {"test_started": "test", "study_started": "study"}

        results = []
        for session in abandoned_sessions:
            first_event_details = {}  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∫ –ø—É—Å—Ç–æ–π dict
            client_ip = "N/A"
            user_info_from_event = {}  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∫ –ø—É—Å—Ç–æ–π dict
            if session.first_event_details_text:
                try:
                    first_event_details = json.loads(session.first_event_details_text)
                    if isinstance(first_event_details, dict):
                        client_ip = first_event_details.get("ip", "N/A")
                        user_info_from_event = first_event_details.get("userInfo", {})
                    else:
                        current_app.logger.warning(
                            f"Parsed details is not a dict for session {session.session_id}"
                        )
                        first_event_details = {}  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –¥–æ –ø—É—Å—Ç–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è
                        user_info_from_event = {}
                except (json.JSONDecodeError, TypeError) as e:
                    current_app.logger.warning(
                        f"Could not parse details text for session {session.session_id}: {e}"
                    )
                    first_event_details = {}  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –¥–æ –ø—É—Å—Ç–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è
                    user_info_from_event = {}
            # --- –õ–û–ì–ò–ö–ê –û–ü–†–ï–î–ï–õ–ï–ù–ò–Ø USER INFO ---
            user = users_map.get(session.persistent_id)

            if user:
                # 1. –õ—É—á—à–∏–π —Å–ª—É—á–∞–π: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–π–¥–µ–Ω –≤ —Ç–∞–±–ª–∏—Ü–µ users
                user_info = {"lastName": user.lastname, "firstName": user.firstname}
            elif user_info_from_event and user_info_from_event.get("lastName"):
                # 2. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–µ—Ç, –Ω–æ –µ—Å—Ç—å userInfo –≤ –¥–µ—Ç–∞–ª—è—Ö —Å–æ–±—ã—Ç–∏—è
                user_info = {
                    "lastName": user_info_from_event.get("lastName", "N/A"),
                    "firstName": user_info_from_event.get("firstName", "N/A"),
                    # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –æ—Ç—á–µ—Å—Ç–≤–æ –∏ –¥–æ–ª–∂–Ω–æ—Å—Ç—å, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                    # 'middleName': user_info_from_event.get('middleName'),
                    "source": "event_log",
                }
                # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–º–µ—Ç–∫—É, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –∏–∑ –ª–æ–≥–∞
            elif session.persistent_id:
                # 3. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–µ—Ç, userInfo –≤ —Å–æ–±—ã—Ç–∏–∏ –Ω–µ—Ç, –Ω–æ –µ—Å—Ç—å persistent_id
                user_info = {
                    "lastName": "N/A",
                    "firstName": f"ID: {str(session.persistent_id)[:8]}...",
                }
            else:
                # 4. –°–æ–≤—Å–µ–º –Ω–∏—á–µ–≥–æ –Ω–µ—Ç
                user_info = {"lastName": "N/A", "firstName": "N/A"}
            # --- –ö–û–ù–ï–¶ –õ–û–ì–ò–ö–ò –û–ü–†–ï–î–ï–õ–ï–ù–ò–Ø USER INFO ---

            results.append(
                {
                    "sessionId": session.session_id,
                    "sessionType": session_type_map.get(
                        session.session_type, "unknown"
                    ),
                    "startTime": (
                        session.start_time.isoformat() if session.start_time else "N/A"
                    ),
                    "userInfo": user_info,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ–±—Ä–∞–Ω–Ω—ã–π userInfo
                    "clientIp": client_ip,
                    "violationCounts": {
                        "focusLoss": session.focus_loss_count or 0,
                        "screenshots": session.screenshot_count or 0,
                        "prints": session.print_count or 0,
                    },
                }
            )

        current_app.logger.info(
            f"Returning {len(results)} abandoned/unsuccessful sessions (safe JSON parsing)"
        )
        return jsonify(results), 200

    except (
        DBAPIError
    ) as e:  # –õ–æ–≤–∏–º –æ—à–∏–±–∫–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö (–≤–∫–ª—é—á–∞—è –æ—à–∏–±–∫–∏ SQL —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞/—Ç–∏–ø–æ–≤)
        db.session.rollback()
        current_app.logger.error(
            f"Database error in get_abandoned_sessions: {e}", exc_info=True
        )
        return (
            jsonify({"status": "error", "message": "Database error during analysis"}),
            500,
        )
    except Exception as e:
        db.session.rollback()  # –û—Ç–∫–∞—Ç –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
        current_app.logger.error(
            f"Unexpected error in get_abandoned_sessions: {e}", exc_info=True
        )
        return jsonify({"status": "error", "message": "Internal server error"}), 500


@api_bp.route("/global_search", methods=["GET"])
@admin_required
@cache.cached(timeout=60, query_string=True)
def global_search():
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –∏ —Å–µ—Å—Å–∏—è–º."""
    query = request.args.get("q", "")

    if not query or len(query) < 3:
        return jsonify(
            {"users": [], "sessions": []}
        )  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –∫–æ—Ä–æ—Ç–∫–∏–π

    search_term = f"%{query}%"

    results = {"users": [], "sessions": []}

    # 1. –ü–æ–∏—Å–∫ –ø–æ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º
    users = (
        User.query.filter(
            or_(
                User.lastname.ilike(search_term),
                User.firstname.ilike(search_term),
                User.middlename.ilike(search_term),
            )
        )
        .limit(5)
        .all()
    )

    for user in users:
        results["users"].append(
            {"id": user.id, "name": user.full_name, "position": user.position}
        )

    # 2. –ü–æ–∏—Å–∫ –ø–æ –°–µ—Å—Å–∏—è–º
    sessions = (
        ResultMetadata.query.filter(
            or_(
                ResultMetadata.session_id.ilike(search_term),
                ResultMetadata.client_ip.ilike(search_term),
                ResultMetadata.document_number.ilike(search_term),
            )
        )
        .limit(5)
        .all()
    )

    for session in sessions:
        results["sessions"].append(
            {
                "id": session.session_id,
                "type": session.test_type,
                "date": session.start_time.isoformat() if session.start_time else "N/A",
            }
        )

    return jsonify(results)


def get_stats_for_period(start_date, end_date, settings):
    """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥."""

    # –ë–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º –ø–µ—Ä–∏–æ–¥–µ
    query = ResultMetadata.query.filter(
        ResultMetadata.end_time.isnot(None),
        ResultMetadata.score.isnot(None),
        ResultMetadata.user_id.isnot(None),
        ResultMetadata.end_time >= start_date,
        ResultMetadata.end_time < end_date,
    )

    # 1. –í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤
    total_tests = query.count()

    # 2. –°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª
    avg_score_result = query.with_entities(func.avg(ResultMetadata.score)).scalar()
    avg_score = round(float(avg_score_result), 1) if avg_score_result else 0

    # 3. –ê–Ω–æ–º–∞–ª–∏–∏
    # –î–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ –∞–Ω–æ–º–∞–ª–∏–π –Ω–∞–º –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    results = query.all()
    anomalies_count = 0
    if results:
        # –≠—Ç–∞ –ª–æ–≥–∏–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —Å –≤–∞—à–∏–º frontend/settings
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º .get('totalFocusLoss', 0) > X, —Ç–∞–∫ –∫–∞–∫ raw_data –º–æ–∂–µ—Ç –Ω–µ –∏–º–µ—Ç—å —ç—Ç–∏—Ö –ø–æ–ª–µ–π
        focus_threshold = settings.get("focusThreshold", 5)
        blur_threshold = settings.get("blurThreshold", 60)
        print_threshold = settings.get("printThreshold", 0)

        for r in results:
            sm = (r.raw_data or {}).get("sessionMetrics", {})
            focus_loss = sm.get("totalFocusLoss", 0)
            blur_time = sm.get("totalBlurTime", 0)
            print_attempts = sm.get("printAttempts", 0)

            if (
                focus_loss > focus_threshold
                or blur_time > blur_threshold
                or print_attempts > print_threshold
            ):
                anomalies_count += 1

    # 4. –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏
    unique_users = query.with_entities(
        func.count(distinct(ResultMetadata.user_id))
    ).scalar()

    return {
        "totalTests": total_tests,
        "avgScore": avg_score,
        "anomaliesCount": anomalies_count,
        "uniqueUsers": unique_users,
    }


def calculate_change(current, previous):
    """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ % –∏–∑–º–µ–Ω–µ–Ω–∏—è."""
    if previous == 0:
        return 100.0 if current > 0 else 0.0  # –†–æ—Å—Ç –Ω–∞ 100%, –µ—Å–ª–∏ –±—ã–ª–æ 0, –∞ —Å—Ç–∞–ª–æ > 0
    change = ((current - previous) / previous) * 100
    return round(change, 1)


@api_bp.route("/get_dashboard_stats", methods=["GET"])
@admin_required
@cache.memoize(timeout=3600)  # –ö—ç—à–∏—Ä—É–µ–º –Ω–∞ 1 —á–∞—Å
def get_dashboard_stats():
    """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –≤–∏–¥–∂–µ—Ç–æ–≤ –¥–∞—à–±–æ—Ä–¥–∞."""
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏, —á—Ç–æ–±—ã –∑–Ω–∞—Ç—å –ø–æ—Ä–æ–≥–∏ –∞–Ω–æ–º–∞–ª–∏–π
        # –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ, —Ç.–∫. —É –Ω–∞—Å –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ 'settings' –∏–∑ state.js
        # –õ—É—á—à–µ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ current_app.config
        settings = {
            "focusThreshold": current_app.config.get("FOCUS_THRESHOLD", 5),
            "blurThreshold": current_app.config.get("BLUR_THRESHOLD", 60),
            "printThreshold": current_app.config.get("PRINT_THRESHOLD", 0),
        }

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–∏–æ–¥—ã
        now = datetime.now(UTC)
        current_period_start = now - timedelta(days=7)
        previous_period_start = now - timedelta(days=14)

        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        current_stats = get_stats_for_period(current_period_start, now, settings)
        previous_stats = get_stats_for_period(
            previous_period_start, current_period_start, settings
        )

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
        response = {
            "totalTests": {
                "value": current_stats["totalTests"],
                "change": calculate_change(
                    current_stats["totalTests"], previous_stats["totalTests"]
                ),
            },
            "avgScore": {
                "value": current_stats["avgScore"],
                "change": calculate_change(
                    current_stats["avgScore"], previous_stats["avgScore"]
                ),
            },
            "anomaliesCount": {
                "value": current_stats["anomaliesCount"],
                "change": calculate_change(
                    current_stats["anomaliesCount"], previous_stats["anomaliesCount"]
                ),
            },
            "uniqueUsers": {
                "value": current_stats["uniqueUsers"],
                "change": calculate_change(
                    current_stats["uniqueUsers"], previous_stats["uniqueUsers"]
                ),
            },
        }

        return jsonify(response), 200

    except Exception as e:
        current_app.logger.error(f"Error in get_dashboard_stats: {e}", exc_info=True)
        return jsonify({"status": "error", "message": "Failed to calculate stats"}), 500
